import openai
from danswer.configs.model_configs import GEN_AI_API_KEY
openai.api_key = GEN_AI_API_KEY


def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0,  # this is the degree of randomness of the model's output
    )
    return response.choices[0].message["content"]


def get_completion_mock(prompt, model="gpt-3.5-turbo"):
    return '''消息id|消息类型|咨询id
807|1|1
808|3|1
809|2|1
810|2|1
811|1|2
812|1|2
813|3|2
814|4|2
815|0|0
816|0|0
817|0|0
818|0|0
819|0|0
820|0|0
821|0|0
822|0|0
823|1|3
824|4|3
825|0|0
826|0|0
827|0|0
828|0|0
829|1|4
830|2|4
831|0|0
832|1|5
833|4|5
834|0|0
835|1|6
836|1|6
837|4|6
838|4|6
839|4|6
840|4|6
841|1|7
842|0|0'''


if __name__ == "__main__":
    prompt = '''下文双反单引号中的文本是一个数据库用户群的聊天记录，每一行是一个聊天消息，格式为：“消息id”|”发送人“|“消息时间”|”消息内容“。    这些消息是用户对数据库的使用和技术方面的咨询，有数据库专家进行答疑。    由于用户很多，不同用户的咨询和答疑消息相互穿插，你的任务是将聊天记录分成不同的咨询记录。    将结果以表格的方式给出,字段间以“|”分隔。    包括5个字段：”消息id“，”消息类型“，”咨询id“。    ”咨询id“为uuid，由你生成，所有属于同一次咨询的消息有同一个咨询id。    ”消息类型“有五种取值，分别为：”用户提问“记为1、“用户补充”记为2、“专家追问”记为3、“专家回答”记为4、“其他”记为0。    ”用户提问“表示用户的咨询问题，每一次咨询，都以用户的咨询问题开始。    “用户补充”表示用户对咨询问题的补充说明，或是对“专家追问”的回答。     “专家追问”表示专家针对用户的咨询问题进行追问，以获取更多用户问题的细节。    “专家回答”表示专家对用户咨询问题的解答。    “其他”表示不属于某次用户咨询，可能只是闲聊，或是消息通知，对于“其他”类型的消息，”咨询id“记为NULL。    做这个任务的时候，注意识别用户和专家两个角色，进行用户提问和用户补充的发送人是用户，追问和回答的是专家，在一次咨询中，用户和专家身份不会变。
``204|鲨鱼辣椒|2023/09/05 09:29|刚刚发布的doris2.0.1，是否修复了只有一台fe的情况下，不能通过jdbc连接fe的bug呀
205|selectdb 李仕杨|2023/09/05 09:30|这个之前有问题吗？@鲨鱼辣椒
206|张家锋|2023/09/05 09:30|这个没有
207|张家锋|2023/09/05 09:30|你是没有添加be的情况下，使用jdbc或者navicat连接doris是吧
208|鲨鱼辣椒|2023/09/05 09:31|嗯嗯  我在只启动了一台fe的情况下，通过jdbc连接FE，注册be
209|鲨鱼辣椒|2023/09/05 09:31|连接不上
210|张家锋|2023/09/05 09:32|这个正在修复
211|张家锋|2023/09/05 09:32|目前需要你使用MySQL命令行连接，构建好集群
212|发子|2023/09/05 09:49|开测了，好速度
213|牛掰格拉斯|2023/09/05 09:55|2.0.1版本安装包的wget地址可以发下吗
214|向光|2023/09/05 09:55|官网有
215|向光|2023/09/05 09:55|https://doris.apache.org/zh-CN/download
216|哆啦A梦|2023/09/05 09:55|可以
217|牛掰格拉斯|2023/09/05 09:56|我要用wget下载
218|向光|2023/09/05 09:56|https://apache-doris-releases.oss-accelerate.aliyuncs.com/apache-doris-2.0.1-bin-x64.tar.gz
219|牛掰格拉斯|2023/09/05 09:56|感谢  我去玩了
220|Skipper|2023/09/05 10:28|2.01 建议上生产么
221|苏奕嘉@SelectDB|2023/09/05 10:28|可以
222|TY|2023/09/05 10:28|0.0
223|TY|2023/09/05 10:28|先测试
224|TY|2023/09/05 10:29|再上生产
225|TY|2023/09/05 10:29|有问题还得换
226|虾米🐳|2023/09/05 10:29|怎么在建动态分区表的时候 就把历史分区也带上啊
227|虾米🐳|2023/09/05 10:30|我现在是SET ("dynamic_partition.enable" = "false") 然后一条一条插
228|向阳而生|2023/09/05 10:31|[图片]
229|虾米🐳|2023/09/05 10:33|这个-12 如果是几年前开始 就换算成天就行吗
230|张英杰-深圳_doris-1.2.6|2023/09/05 10:34|尽量少用天分区，用月或周分区
231|虾米🐳|2023/09/05 10:34|有什么说法吗
232|Dearest|2023/09/05 10:36|为什么
233|Dearest|2023/09/05 10:36|天分区的场景才是最多吧
234|张英杰-深圳_doris-1.2.6|2023/09/05 10:38|天分区会有大量的tablet生成，对系统稳定性造成一定影响
235|张英杰-深圳_doris-1.2.6|2023/09/05 10:38|不知道现在有没有解决
236|苏奕嘉@SelectDB|2023/09/05 10:38|要看你分区多少了
237|苏奕嘉@SelectDB|2023/09/05 10:39|主流就是用天分区呀
238|牛掰格拉斯|2023/09/05 10:39|新发行的2.0.1安装后，这里显示的版本是对的吗
239|牛掰格拉斯|2023/09/05 10:39|[图片]
240|虾米🐳|2023/09/05 10:39|我目前场景分的比较多  基本都是从2022年1月开始 至今
241|苏奕嘉@SelectDB|2023/09/05 10:39|对的
242|牛掰格拉斯|2023/09/05 10:39|en
243|虾米🐳|2023/09/05 10:39|2021年
244|虾米🐳|2023/09/05 10:39|快上千分区
245|苏奕嘉@SelectDB|2023/09/05 10:40|你这个上千分区的话，热数据是多大范围内的？
246|虾米🐳|2023/09/05 10:40|就是分区这一块 还沿用了hive的分区习惯
247|苏奕嘉@SelectDB|2023/09/05 10:41|如果你查询热数据，也就半年的，那我建议你可以定期做做合并
248|苏奕嘉@SelectDB|2023/09/05 10:41|比如一年前的做月度分区
249|苏奕嘉@SelectDB|2023/09/05 10:41|半年到一年做周
250|虾米🐳|2023/09/05 10:41|有几个比较极端的表  是百亿  基本都是全表搜   大部分热数据估计就几十万  就是比较靠近现在的采用
251|虾米🐳|2023/09/05 10:43|这个能实现自动么
252|苏奕嘉@SelectDB|2023/09/05 10:43|当前不能
253|苏奕嘉@SelectDB|2023/09/05 10:43|一个月你才执行一次……
254|苏奕嘉@SelectDB|2023/09/05 10:43|写个脚本~
255|苏奕嘉@SelectDB|2023/09/05 10:44|创建临时分区->导入数据->删除老分区
256|虾米🐳|2023/09/05 10:44|分区能修改么  还是  果断时间就重新建表写数据
257|苏奕嘉@SelectDB|2023/09/05 10:44|就这么三步，搞个sql脚本就完事了
258|苏奕嘉@SelectDB|2023/09/05 10:45|https://doris.apache.org/zh-CN/docs/dev/advanced/partition/table-temp-partition
259|苏奕嘉@SelectDB|2023/09/05 10:45|看这个
260|虾米🐳|2023/09/05 10:47|我看看
261|虾米🐳|2023/09/05 10:47|这个好像是-12天以前的不保留吧
262|虾米🐳|2023/09/05 10:48|@苏奕嘉@SelectDB  这个有简便的办法实现吗
263|张英杰-深圳_doris-1.2.6|2023/09/05 10:49|有个保留参数
264|张英杰-深圳_doris-1.2.6|2023/09/05 10:49|设置一个保留日期，就不会被清掉
265|张英杰-深圳_doris-1.2.6|2023/09/05 10:50|reserved_history_periods
266|虾米🐳|2023/09/05 10:50|我现在是 现在建表 动态分区  不是只有未来和今天的分区吗
267|虾米🐳|2023/09/05 10:51|怎么在建表的时候 过去的分区也能建立
268|张英杰-深圳_doris-1.2.6|2023/09/05 10:51|start设置的多一点
269|虾米🐳|2023/09/05 10:51|负数吗
270|张英杰-深圳_doris-1.2.6|2023/09/05 10:51|设置100个，建表时就会创建103个分区
271|张英杰-深圳_doris-1.2.6|2023/09/05 10:51|对
272|虾米🐳|2023/09/05 10:51|刚才试了 -977  发现没有啊
273|张英杰-深圳_doris-1.2.6|2023/09/05 10:52|那应该还有个其他参数制约，看看官网
274|张英杰-深圳_doris-1.2.6|2023/09/05 10:52|或者就是分区太多，创建不过来，看看fe日志有没有报错
275|向阳而生|2023/09/05 10:54|你把你建表语句发出来看
276|虾米🐳|2023/09/05 10:56|PARTITION BY RANGE(CREATE_TIME)()，DISTRIBUTED BY HASH( `SN` )BUCKETS 10，PROPERTIES (，"replication_allocation" = "tag.location.default: 3",，"dynamic_partition.enable" = "true",，"dynamic_partition.time_unit" = "DAY",，"dynamic_partition.start" = "-977",，"dynamic_partition.end" = "3",，"dynamic_partition.prefix" = "p",，"dynamic_partition.buckets" = "10"，)
277|向阳而生|2023/09/05 10:56|"dynamic_partition.create_history_partition"= "true",
278|向阳而生|2023/09/05 10:57|加上就可以了
279|虾米🐳|2023/09/05 10:58|但是这个
280|虾米🐳|2023/09/05 10:58|[图片]
281|虾米🐳|2023/09/05 10:58|这个不是设置 多久保留吗
282|向阳而生|2023/09/05 10:59|[图片]
283|向阳而生|2023/09/05 11:00|history_partition_num 默认是-1
284|向阳而生|2023/09/05 11:02|文档 + 示例 还是比较容易看懂
285|虾米🐳|2023/09/05 11:04|我试试
286|向阳而生|2023/09/05 11:08|主要就是这里
287|向阳而生|2023/09/05 11:08|[图片]
288|光风霁月|2023/09/05 11:11|[图片]
289|光风霁月|2023/09/05 11:11|mac编译doris报错
290|光风霁月|2023/09/05 11:11|同志们，有解么
291|Petrichor|2023/09/05 11:11|x86_64
292|Petrichor|2023/09/05 11:11|[流泪]
293|哆啦A梦|2023/09/05 11:12|[捂脸]
294|光风霁月|2023/09/05 11:12|我这电脑也不是M1 的，是Intel的
295|Petrichor|2023/09/05 11:12|第三方库是不拉取错了
296|光风霁月|2023/09/05 11:13|按照官网拉了第三方库了
297|向光|2023/09/05 11:13|在master分支上直接编译的？
298|光风霁月|2023/09/05 11:13|[图片]
299|光风霁月|2023/09/05 11:14|官网下的
300|虾米🐳|2023/09/05 11:14|我弄100试了下 成功了  但是现在需求要超过500天的  是不是就没办法了
301|向光|2023/09/05 11:15|你可以把第三方库删了 直接编译
302|哆啦A梦|2023/09/05 11:15|max_dynamic_partition_num 这个可以改一下
303|Petrichor|2023/09/05 11:16|你这个第三发库要拉2.0 的
304|光风霁月|2023/09/05 11:17|[图片]
305|光风霁月|2023/09/05 11:17|这个是2.0的么
306|Petrichor|2023/09/05 11:18|https://github.com/apache/doris-thirdparty/releases/tag/automation-2.0
307|Petrichor|2023/09/05 11:19|这个是master 用的
308|光风霁月|2023/09/05 11:20|[OK]
309|虾米🐳|2023/09/05 11:23|这个怎么修改啊？
310|虾米🐳|2023/09/05 11:24|SET dynamic_partition.max_dynamic_partition_num = 1000  我这样好像不行
311|向阳而生|2023/09/05 11:24|fe
312|张家锋|2023/09/05 11:24|这个是fe配置不是变量
313|向阳而生|2023/09/05 11:24|[图片]
314|虾米🐳|2023/09/05 11:27|好吧 那我只能让我同事改了
315|光风霁月|2023/09/05 12:04|[图片]
316|光风霁月|2023/09/05 12:05|doris 2.0 这两个第三方库的版本对么
317|郭强@SelectDB|2023/09/05 12:06|对着
318|光风霁月|2023/09/05 12:06|嚓，那还是
319|光风霁月|2023/09/05 12:06|这个错
320|光风霁月|2023/09/05 12:06|[图片]
321|郭强@SelectDB|2023/09/05 12:08|你是啥系统啊
322|光风霁月|2023/09/05 13:14|mac intel
323|阿庆|2023/09/05 13:27|咨询一个问题，现有集群是doris 1.2.6版本的，现在想要升级2.0，结果现在发布了1.2.7和2.0.1，这个有没有升级步骤流程呀，还是都可以升级
324|木槿|2023/09/05 13:29|https://doris.apache.org/zh-CN/docs/dev/admin-manual/cluster-management/upgrade/
325|郭强@SelectDB|2023/09/05 13:29|@光风霁月
326|郭强@SelectDB|2023/09/05 13:29|话说你是不是下错了
327|郭强@SelectDB|2023/09/05 13:29|[图片]
328|光风霁月|2023/09/05 13:30|[图片]
329|光风霁月|2023/09/05 13:30|是这个不
330|郭强@SelectDB|2023/09/05 13:31|对
331|郭强@SelectDB|2023/09/05 13:31|我看你截图似乎是master的
332|光风霁月|2023/09/05 13:31|我刚才又下了一遍
333|发子|2023/09/05 13:34|大佬们来聊聊2.0.1测试感觉呗
334|光风霁月|2023/09/05 13:47|刚才的问题解决了，应该是我第三方依赖库放错文件夹了
335|光风霁月|2023/09/05 13:47|[图片]
336|光风霁月|2023/09/05 13:48|但是现在又报这个错。。。
337|哆啦A梦|2023/09/05 13:55|@光风霁月 私聊看下
338|光风霁月|2023/09/05 13:56|已加
339|牛掰格拉斯|2023/09/05 13:58|2.0.1版本的指标变成这个了？我记得之前是doris_be_disks_data_used_capacity呢，这个为啥变了呢
340|牛掰格拉斯|2023/09/05 13:58|[图片]
341|守岩|2023/09/05 14:24|问一个小白问题：doris 支持oltp么？
342|苏奕嘉@SelectDB|2023/09/05 14:25|不支持
343|守岩|2023/09/05 14:27|[OK]
344|守岩|2023/09/05 14:31|[图片]
345|守岩|2023/09/05 14:33|[图片]
346|守岩|2023/09/05 14:34|[图片]
347|WZ-郑州-1.2.4|2023/09/05 14:50|detailMessage = Unsupported type 'UNSUPPORTED_TYPE' in '`jdbc_postgresql`.`default_cluster:mapi_report`.`cms_report_video_day`.`label`'.，问一下，PG外部表中有字段是json，在doris中没法读，大佬们咋处理的
348|Petrichor|2023/09/05 14:55|你这个版本是多少？
349|南方有乔木|2023/09/05 14:56|datax向doris插入数据时报错
350|南方有乔木|2023/09/05 14:56|[图片]
351|南方有乔木|2023/09/05 14:57|"[INTERNAL_ERROR]too many filtered rows"
352|南方有乔木|2023/09/05 14:57|这是为啥
353|mcfly|2023/09/05 14:57|@WZ json直接定义成字符串类型就行了。
354|Petrichor|2023/09/05 14:57|打开http://192. 那个连接
355|WZ-郑州-1.2.4|2023/09/05 14:58|1.2.4
356|WZ-郑州-1.2.4|2023/09/05 14:58|主要我们的pg业务库没法改字段类型的
357|WZ-郑州-1.2.4|2023/09/05 14:58|@Petrichor
358|Petrichor|2023/09/05 14:59|我看看啊
359|虾米🐳|2023/09/05 15:41|Compound predicate's op should be AND
360|虾米🐳|2023/09/05 15:41|DELETE FROM ods.ods_wms_pack_entity，WHERE (substr(DATA_SOURCE,1,2) <> 'LZ' or DATA_SOURCE is null)
361|虾米🐳|2023/09/05 15:41|这个写法不行么
362|虾米🐳|2023/09/05 15:41|UNIQUE  没有分区
363|秦浩|2023/09/05 15:46|请教一下，aggregate表的预聚合计算，是导入时做的还是compaction时做的？或者是读的时候做的？
364|Why!Not！！！|2023/09/05 15:46|read
365|Why!Not！！！|2023/09/05 15:47|他的模型应该merge on read
366|秦浩|2023/09/05 16:45|也就是导入时不做聚合预计算？
367|阿庆|2023/09/05 16:48|doris 1.2.6直接升级到2.0.1，有哪位道友试过
368|张家锋|2023/09/05 16:49|可以
369|哆啦A梦|2023/09/05 16:49|没问题，直接升级就行了
370|阿庆|2023/09/05 16:49|ok，这周把生产用的doris集群升级一下
371|张家锋|2023/09/05 16:50|建议你先测试一下
372|张家锋|2023/09/05 16:50|然后再升级生产
373|mcfly|2023/09/05 16:50|@WZ 是你的目标doris表改成string类型，业务库当然别动
374|WZ-郑州-1.2.4|2023/09/05 16:51|好的
375|WZ-郑州-1.2.4|2023/09/05 16:52|弱弱的问一下大佬们，我们原来dws层报表通过jdbc外表导入到doris，数据大概在2-3kw 建议在哪个模型使用啊
376|张家锋|2023/09/05 17:00|unique
377|张家锋|2023/09/05 17:00|你外部数据源是rds，存在变更吗？
378|WZ-郑州-1.2.4|2023/09/05 17:02|有的
379|莱昂纳多·迪卡普里奥焦|2023/09/05 17:10|hello 各位大佬们   我在用Flink  datastream  写入 doris 时  有一个字段是bitmap  我设置了 DorisExecutionOptions.setStreamLoadProp
380|莱昂纳多·迪卡普里奥焦|2023/09/05 17:10|但是依然报错
381|莱昂纳多·迪卡普里奥焦|2023/09/05 17:10|[图片]
382|莱昂纳多·迪卡普里奥焦|2023/09/05 17:10|[图片]
383|莱昂纳多·迪卡普里奥焦|2023/09/05 17:10|Flink 版本  1.15  doris 1.2
384|发子|2023/09/05 17:23|大佬，这个方案好呀
385|无理|2023/09/05 17:24|去掉这个 to_bitmap 呢@莱昂纳多·迪卡普里奥焦
386|无理|2023/09/05 17:24|[图片]
387|莱昂纳多·迪卡普里奥焦|2023/09/05 17:28|还是相同的错
388|无理|2023/09/05 17:29|你表怎么建的
389|莱昂纳多·迪卡普里奥焦|2023/09/05 17:30|[图片]
390|无理|2023/09/05 17:33|connector 啥版本
391|莱昂纳多·迪卡普里奥焦|2023/09/05 17:34|[图片]
392|Simba|2023/09/05 18:05|[图片]
393|Simba|2023/09/05 18:05|要加个别名
394|Alon|2023/09/05 18:08|使用catlog 需要开启什么吗
395|守岩|2023/09/05 18:18|请教个问题，orcale实时抽取数据到doris有啥解决方案
396|赵炳泉 SelectDB|2023/09/05 18:46|直接创建catalog就行
397|哆啦A梦|2023/09/05 18:48|泉哥，他这个是外表
398|赵炳泉 SelectDB|2023/09/05 18:48|doris，哪个版本呀
399|哆啦A梦|2023/09/05 18:48|2.0.0
400|哆啦A梦|2023/09/05 18:49|需要编译
401|赵炳泉 SelectDB|2023/09/05 18:49|能用catalog就直接用catalog吧
402|哆啦A梦|2023/09/05 18:49|okok
403|苏奕嘉@SelectDB|2023/09/05 18:52|Flink-Doris-Connector
404|一个人的理想主义|2023/09/05 19:31|使用2.0.1-rc4这个tag构建，官方推荐使用哪个docker镜像构建？发现docker工具链gcc11.1 已经默认启用Wunused_return会报错，使用往前递推一个tag的构建镜像吗？
``'''
    #res = get_completion(prompt=prompt)
    prompt2 = '''下文双反单引号中的文本是一个数据库用户群的聊天记录，每一行是一个聊天消息，格式为：“消息id”|”发送人“|“消息时间”|”消息内容“。    这些消息是用户对数据库的使用和技术方面的咨询，有数据库专家进行答疑。    由于用户很多，不同用户的咨询和答疑消息相互穿插，你的任务是将聊天记录分成不同的咨询记录。    将结果以表格的方式给出,字段间以“|”分隔。    包括5个字段：”消息id“，”消息类型“，”咨询id“。    ”咨询id“为uuid，由你生成，所有属于同一次咨询的消息有同一个咨询id。    ”消息类型“有五种取值，分别为：”用户提问“记为1、“用户补充”记为2、“专家追问”记为3、“专家回答”记为4、“其他”记为0。    ”用户提问“表示用户的咨询问题，每一次咨询，都以用户的咨询问题开始。    “用户补充”表示用户对咨询问题的补充说明，或是对“专家追问”的回答。     “专家追问”表示专家针对用户的咨询问题进行追问，以获取更多用户问题的细节。    “专家回答”表示专家对用户咨询问题的解答。    “其他”表示不属于某次用户咨询，可能只是闲聊，或是消息通知，对于“其他”类型的消息，”咨询id“记为NULL。    做这个任务的时候，注意识别用户和专家两个角色，进行用户提问和用户补充的发送人是用户，追问和回答的是专家，在一次咨询中，用户和专家身份不会变。'''
    prompt3 = '''下文'''
    prompt4 = "a140e8ac-bb7d-4eec-8150-aceb1f30d946"
    print(len(prompt))
    print(len(prompt2))
    print(len(prompt3))
    print(len(prompt4))

    text = f"""
    8604,1679015210,simple,"问一下，源数据的初始采集模式"
    8605,1679015233,simple,"一般是每次都从头获取吗startupOptions(StartupOptions.initial())"
    8758,1679017997,"满天*@","doris1.2.2对表名，字段名等长度有限制吗？"
    9007,1679023387,"深蓝","请问doris有cdc 日志数据吗"
    9008,1679023412,"深蓝","实时整库同步，如何校验上下游数据一致性，有没有好的思路"
    9024,1679024127,"王磊","只要导入事务没报错，一致性肯定就是OK的。"
    9066,1679025352,"达","大家好，在flink cdc时数据名带一个 - 字符同步不成功有办法搞吗"
    9069,1679025366,"达","现在不好改名[捂脸]"
    9090,1679025605,gneHiL,"数据名是什么，列名吗"
    9093,1679025631,"达","数据库名"
    9096,1679025676,gneHiL,"报什么错啊"
    9101,1679025735,"达","没报错，但是没数据，同一个服务器，没-字符的数据库可以同步"
    9114,1679026215,"满天*@","doris1.2.2对表名，字段名等长度有限制吗？文档没找到相关介绍[捂脸]，有大佬知道不"
    9117,1679026391,"王磊","理论上都够用呀，你是有多长的名字？"
    9206,1679031709,"满天*@","最大64"
    9207,1679031709,"满天*@",""
    9210,1679031938,"王磊","看样子是FE可配置的。"
    9212,1679031999,"满天*@","这个可以配置吗？"
    9213,1679032039,"王磊","ADMIN SET FRONTEND CONFIG (""table_name_length_limit"" = ""xxxx""); 配置下"
    9214,1679032555,"王者Kingdom韬","想问下，doris单表有字段数量限制吗？"
    9215,1679032787,"深蓝","大佬们 这个参数到底怎么设置， 是doris的配置吗"
    9216,1679032788,"深蓝",""
    9217,1679032847,"深蓝","我在网上搜大部分是mysql的配置， 在控台执行set  max_allowed_packet=10*1024*1024; 后查询也解决不了这个问题，查出来的单条数据大于1MB无法显示"
    9307,1679034044,"王者Kingdom韬","好的好的"
    9337,1679035373,simple,"doris 的docker部署跟直接部署效果是一样的吗"
    9338,1679035384,simple,"生产环境适合采用docker部署吗"
    9339,1679035428,"满一","不适合"
    9340,1679035464,simple,"差点搞下去"
    9341,1679035469,simple,"还好"
    9347,1679038498,"王者Kingdom韬","想问下，unique模型表中，sequence字段可以有多个吗？"
    9352,1679038666,"王磊","应该不行，你啥业务啥需求？"
    9363,1679038996,"王者Kingdom韬","原始ODS：登录表--每次用户登录的时间、ip等      充值表--每次用户充值的时间、金额等。   想把这两个表汇总成这种形式 ：  用户id 最后登录时间  最后登录ip  最后付费时间  最后付费金额   "
    9370,1679039205,"王磊","那你这个是部分列更新哈，感觉不需要sequence 哈"
    9373,1679039400,"王者Kingdom韬","要的呀，比如  最后登录时间  最后登录ip   这两个是一起的，取的是最后一次登录时的时间以及对应的ip。这个不就是按照登录时间排序后替换吗？"
    9444,1679042455,darjuan,"哪位大佬有编译好的  seatunnel connector-doris jar包呢"
    9445,1679042575,"王者Kingdom韬","你直接下载官方编译好的包不就好了"
    9449,1679042639,darjuan,"[破涕为笑] 要在服务器上面install"
    9450,1679042648,"满天*@","
    9451,1679042648,"满天*@",""
    9452,1679042651,darjuan,"链接不了外网，只能在本地搞"
    9453,1679042766,"满天*@","那这个能放开限制吗？有计划放开限制吗？"
    9455,1679043077,"","建议你们也别用"
    9467,1679043233,"王者Kingdom韬","[旺柴]这个我觉得主要是doris支持了，不见得其他组件支持"
    9472,1679043323,"","跟其他组件的兼容性也是个问题[旺柴]"
    9473,1679043485,"王者Kingdom韬","踩过坑的我，都是泪[翻白眼]"
    9579,1679046912,"?   ɹ ǝ   n ᴉ?","有人把表truncate了  我怎么才能查操作日志呢？"
    9591,1679047154,"冰山一角","审计日志"
    """
    print(len(text))



"""
openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. 
However, your messages resulted in 7468 tokens. Please reduce the length of the messages.
"""